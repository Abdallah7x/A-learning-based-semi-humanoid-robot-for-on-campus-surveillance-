{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23eb52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import Report_SQL as RS\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "# \thelp=\"path to trained serialized model\")\n",
    "# ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "# \thelp=\"path to  label binarizer\")\n",
    "# ap.add_argument(\"-i\", \"--input\", required=True,\n",
    "# \thelp=\"path to our input video\")\n",
    "# ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "# \thelp=\"path to our output video\")\n",
    "# ap.add_argument(\"-s\", \"--size\", type=int, default=128,\n",
    "# \thelp=\"size of queue for averaging\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d706d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CS\\Graduation Project\\-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main\\Face recognition\n"
     ]
    }
   ],
   "source": [
    "cd E:/CS/Graduation Project/-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main/Face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85adcd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CS\\Graduation Project\\-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main\\Integrated\\Smoking-Dataset\n"
     ]
    }
   ],
   "source": [
    "cd E:/CS/Graduation Project/-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main/Integrated/Smoking-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0375bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CS\\Graduation Project\\-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main\\Integrated\n"
     ]
    }
   ],
   "source": [
    "cd E:/CS/Graduation Project/-A-learning-based-semi-Humanoid-Robot-for-On-campus-Surveillance-main/Integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9795ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n"
     ]
    }
   ],
   "source": [
    " # load the trained model and label binarizer from disk\n",
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "model = load_model(\"CompressedBigResNet.h5\")\n",
    "lb = pickle.loads(open(\"lb.pickle\", \"rb\").read())\n",
    "# initialize the image mean for mean subtraction along with the\n",
    "# predictions queue\n",
    "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "Q = deque(maxlen=15) #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "873928ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f159212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03180271 0.2599735  0.13037853 0.5778453 ]\n",
      "[0.03061852 0.2574281  0.13096188 0.58099157]\n",
      "[0.02935067 0.25244325 0.13068666 0.58751947]\n",
      "[0.02885848 0.24157421 0.12927781 0.6002895 ]\n",
      "[0.02722773 0.23047154 0.12658142 0.6157194 ]\n",
      "[0.02622197 0.22179303 0.12464014 0.6273449 ]\n",
      "[0.02578425 0.21800043 0.1161722  0.6400431 ]\n",
      "[0.02550497 0.21342567 0.11364077 0.6474285 ]\n",
      "[0.02486034 0.20775972 0.10875256 0.65862733]\n",
      "[0.02373298 0.20311971 0.10617016 0.66697717]\n",
      "[0.02173267 0.19533321 0.10433856 0.6785956 ]\n",
      "[0.0206181  0.1875271  0.10356253 0.6882923 ]\n",
      "[0.01964966 0.18444805 0.08589198 0.71001035]\n",
      "1 record inserted, ID: 8\n",
      "[0.01837563 0.17205702 0.07430568 0.7352617 ]\n",
      "1 record inserted, ID: 9\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    " # initialize the video stream, pointer to output video file, and\n",
    "# frame dimensions\n",
    "vs = cv2.VideoCapture(0)#\"pexels-mart-production-7277932.mp4\"\n",
    "writer = None\n",
    "(W, H) = (None, None)\n",
    "# loop over frames from the video file stream\n",
    "\n",
    "while True:\n",
    "\t# read the next frame from the file\n",
    "\t#img_counter+=1\n",
    "\t(grabbed, frame) = vs.read()\n",
    "\t# if the frame was not grabbed, then we have reached the end\n",
    "\t# of the stream\n",
    "\tif not grabbed:\n",
    "\t\tbreak\n",
    "\t# if the frame dimensions are empty, grab them\n",
    "\tif W is None or H is None:\n",
    "\t\t(H, W) = frame.shape[:2]\n",
    "        \n",
    "# clone the output frame, then convert it from BGR to RGB\n",
    "\t# ordering, resize the frame to a fixed 224x224, and then\n",
    "\t# perform mean subtraction\n",
    "\toutput = frame.copy()\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\tframe = cv2.resize(frame, (200, 200)).astype(\"float32\")\n",
    "\tframe -= mean\n",
    "\t# make predictions on the frame and then update the predictions\n",
    "\t# queue\n",
    "\tpreds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "\tQ.append(preds)\n",
    "\t# perform prediction averaging over the current history of\n",
    "\t# previous predictions\n",
    "\tresults = np.array(Q).mean(axis=0)\n",
    "\tprint (results)\n",
    "\ti = np.argmax(results)\n",
    "\tif (i==3) and results[3]<0.70000000:\n",
    "\t\t\n",
    "\t\tresults[3]=0\n",
    "# \tif label == \"Smoking\":\n",
    "# \t\tlabel = \"Normal\"\n",
    "\t# draw the activity on the output frame\n",
    "\ti = np.argmax(results) #label=\"Normal\" \n",
    "\tlabel = lb.classes_[i]\n",
    "\ttext = \"activity: {}\".format(label)\n",
    "\tcv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\t# check if the video writer is None\n",
    "\tim= \"Detected_Frame_{}.png\".format(img_counter)\n",
    "\tif label!=\"Normal\":\n",
    "\t\tcv2.imwrite(im, output)\n",
    "\t\tRS.report(im,label)\n",
    "\tif writer is None:\n",
    "\t\t# initialize our video writer\n",
    "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\t#writer = cv2.VideoWriter(\"tennis_128frames_smoothened.avi\", fourcc, 30, (W, H), True)\n",
    "\t# write the output frame to disk\n",
    "\t#writer.write(output)\n",
    "\t# show the output image\n",
    "\tcv2.imshow(\"Output\", output)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "# release the file pointers\n",
    "print(\"[INFO] cleaning up...\")\n",
    "#writer.release()\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d812882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
