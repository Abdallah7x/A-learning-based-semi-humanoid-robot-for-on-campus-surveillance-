{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHRU-m1Ubgh8"
   },
   "source": [
    "**Mounting and Going to The Directory Of the YOLOV5 Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "L1FuwkvFSBI8",
    "outputId": "0fd67415-ecef-4736-9d2e-2b3791cabe79"
   },
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcoLX3LSbc0a",
    "outputId": "e125bb45-35eb-4d25-dd91-e02eeaad1c1f"
   },
   "outputs": [],
   "source": [
    "#%cd YOLOV5/yolov5\n",
    "#! wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5x6.pt\n",
    "\n",
    "#!pip install -r requirements.txt \n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoYLVH5jAs8E",
    "outputId": "a4e34ced-dc71-4ec1-9ffb-ce9ada2bbd92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v6.0-162-gaffa284 torch 1.10.1 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (4 CPUs, 7.9 GB RAM, 144.8/151.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from yolov5 import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKve1y3EaUly"
   },
   "source": [
    "**To Install Packges In Colab Permanently Use These 2 upcoming Cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3GU6fL4LYIA"
   },
   "outputs": [],
   "source": [
    "#nb_path = '/content/notebooks'\n",
    "#os.symlink('/content/drive/MyDrive/Colab Notebooks', nb_path)\n",
    "#sys.path.insert(0, nb_path)  # or append(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmYBlTcJajkm",
    "outputId": "3451fee5-5483-46c0-d869-859a5151c462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-03 09:12:37--  https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5m.pt\n",
      "Resolving github.com (github.com)... 52.69.186.44\n",
      "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/0c5931c4-1273-4bc0-bd56-5c9da71cd35b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220103T091237Z&X-Amz-Expires=300&X-Amz-Signature=133348cae509611557260baeecf87e4b0cc7651f3877d8c4f80b62c6ad18db37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-01-03 09:12:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/0c5931c4-1273-4bc0-bd56-5c9da71cd35b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220103T091237Z&X-Amz-Expires=300&X-Amz-Signature=133348cae509611557260baeecf87e4b0cc7651f3877d8c4f80b62c6ad18db37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42696883 (41M) [application/octet-stream]\n",
      "Saving to: â€˜yolov5m.pt.1â€™\n",
      "\n",
      "yolov5m.pt.1        100%[===================>]  40.72M  15.0MB/s    in 2.7s    \n",
      "\n",
      "2022-01-03 09:12:41 (15.0 MB/s) - â€˜yolov5m.pt.1â€™ saved [42696883/42696883]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%pip install -qr --target=$nb_path requirements.txt\n",
    "#!pip install --target=$nb_path wandb\n",
    "\n",
    "#!unrar x \"/content/drive/MyDrive/Datasets/Biggest_Dataset.rar\" \"/content/drive/MyDrive/Datasets\"\n",
    "!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5m.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pnWOYhjamJo"
   },
   "source": [
    "**Train The Model Giving The *.yaml File We Edited To Route Our Train and validate dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cUJy-ZZN3xL",
    "outputId": "c85e3df2-ab87-473c-f043-11b80301d734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 34, in <module>\n",
      "    import val  # for end-of-epoch mAP\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/val.py\", line 26, in <module>\n",
      "    from models.common import DetectMultiBackend\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/models/common.py\", line 23, in <module>\n",
      "    from utils.datasets import exif_transpose, letterbox\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/utils/datasets.py\", line 28, in <module>\n",
      "    from utils.augmentations import Albumentations, augment_hsv, copy_paste, letterbox, mixup, random_perspective\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/utils/augmentations.py\", line 12, in <module>\n",
      "    from utils.general import LOGGER, check_version, colorstr, resample_segments, segment2box\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/utils/general.py\", line 29, in <module>\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!python train.py --img 640 --batch 16 --epochs 60 --data custom_data.yaml --weights yolov5s.pt --cache\n",
    "!python train.py --img 640 --batch 12 --epochs 300 --data /content/drive/MyDrive/Datasets/Biggest_Dataset/custom_data.yaml --weights /content/drive/MyDrive/yolov5/content/yolov5/yolov5s.pt --cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZuEjdVWa5A7"
   },
   "source": [
    "**New Detection --Source 0 For webCam Detection or use --Source url to test Image or vidio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zKOgesCkvhJ",
    "outputId": "f339846e-481d-4471-89e0-3dfdbb411c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/drive/MyDrive/yolov5/content/yolov5/cards.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.0-162-gaffa284 torch 1.10.0+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "image 1/1 /content/drive/MyDrive/yolov5/content/yolov5/cards.jpg: 480x640 1 Playing-Card, Done. (0.387s)\n",
      "Speed: 2.5ms pre-process, 387.5ms inference, 15.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!python detect.py --weights /content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp2/weights/best.pt --img 1280 --conf 0.25 --source /content/drive/MyDrive/yolov5/content/yolov5/cards.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj8KP3YZb1Ac"
   },
   "source": [
    "**Validating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdYuihl6VioH",
    "outputId": "aed72560-763c-4dca-fd3a-af611f8798ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/yolov5/content/yolov5/data/custom_data.yaml, weights=['/content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp2/weights/last.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
      "YOLOv5 ðŸš€ v6.0-162-gaffa284 torch 1.10.0+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['/content/drive/MyDrive/yolov5/content/train_data/test/images']\n",
      "Traceback (most recent call last):\n",
      "  File \"val.py\", line 370, in <module>\n",
      "    main(opt)\n",
      "  File \"val.py\", line 343, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"val.py\", line 142, in run\n",
      "    data = check_dataset(data)  # check\n",
      "  File \"/content/drive/MyDrive/yolov5/content/yolov5/utils/general.py\", line 416, in check_dataset\n",
      "    raise Exception('Dataset not found.')\n",
      "Exception: Dataset not found.\n"
     ]
    }
   ],
   "source": [
    "#!python val.py --weights /content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp2/weights/best.pt --data /content/drive/MyDrive/yolov5/content/yolov5/data/custom_data.yaml --img 640 --iou 0.65 --half --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yVUmpZcrKSk"
   },
   "source": [
    "**Plotting The Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIp6T6JuF1Ep",
    "outputId": "bed563cd-d84d-482a-bf61-2bef2e137176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp2/weights/last.pt'], source=0, imgsz=[640, 640], conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ 2021-12-31 torch 1.10.0+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays\n",
      "cv2.imshow() is disabled in Google Colab environments\n",
      "[ WARN:0] global /io/opencv/modules/videoio/src/cap_v4l.cpp (802) open VIDEOIO ERROR: V4L: can't open camera by index 0\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 243, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 238, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 92, in run\n",
      "    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)\n",
      "  File \"/content/drive/My Drive/yolov5/content/yolov5/utils/datasets.py\", line 308, in __init__\n",
      "    assert cap.isOpened(), f'{st}Failed to open {s}'\n",
      "AssertionError: 1/1: 0... Failed to open 0\n"
     ]
    }
   ],
   "source": [
    "#from utils.plots import plot_results\n",
    "#plot_results('/content/drive/MyDrive/yolov5/content/yolov5/runs/train/exp3/results.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bYJfKfBDjHf"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/yolov5/content/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvXWVd0PXaRr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YoloV5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
